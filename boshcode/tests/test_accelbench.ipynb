{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../cnn_design-space/cnnbench/')\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "from six.moves import cPickle as pickle\n",
    "import hashlib\n",
    "import subprocess\n",
    "\n",
    "from library import GraphLib, Graph\n",
    "from utils import print_util as pu\n",
    "import manual_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ops found outside config\n"
     ]
    }
   ],
   "source": [
    "config_file_path = '../../cnn_design-space/cnnbench/tests/config_all-ops.yaml'\n",
    "\n",
    "models_mini = ['vgg11', 'vgg13', 'vgg16', 'vgg19', 'resnet18', 'resnet34', \n",
    "               'resnet50', 'resnet101', 'resnet152', 'shufflenet', 'mobilenet', 'googlenet',\n",
    "               'inception', 'xception']\n",
    "\n",
    "with open(config_file_path) as config_file:\n",
    "    try:\n",
    "        config = yaml.safe_load(config_file)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "ops = []\n",
    "\n",
    "for model_name in models_mini:\n",
    "    model = manual_models.get_manual_graph(config, model_name=model_name)\n",
    "    for module in model.graph:\n",
    "        ops.extend(module[1])\n",
    "        \n",
    "ops = list(set(ops))\n",
    "\n",
    "for op in ops:\n",
    "    assert op in config['base_ops'] + config['dense_ops'] + config['flatten_ops'] \\\n",
    "        + ['dense_classes', 'input', 'output'], \\\n",
    "        f'{op} not in config'\n",
    "    \n",
    "print('No ops found outside config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg11: ad0a60f4a4077a823e03c806612b1739d7dbdcb9955a77b582d18ba9eea0a6b8\n",
      "vgg13: 6d0862109b4bd4ba489ae97bc9f675734fc2a6a54a210b3a4f391fa01889a982\n",
      "vgg16: c02c2fde320d179d81af17833c9466bfbfbb1facb42d82e14e9793a9b1ae7979\n",
      "vgg19: 2bc7895ec217f994d1d1bec034626be9a9f68848c97d62f7e1c493cc8c73330b\n",
      "resnet18: 1da03cb835aa34f8ccbe0ecf6a025ff9e4f8536e1e1713e9a93c65523b7d885a\n",
      "resnet34: 0b46c0d8566133b428ec736bea72c8b7eda7e79d477f54c587c1f6a521611998\n",
      "resnet50: 3abff4667b9e17a30f71ad57a6f7d52d217283984e81a878fceabeb43d299114\n",
      "resnet101: 4021dbdb0a51fcfab78d87515f07ece1227696d97260b019a76810ba60f5ed03\n",
      "resnet152: e1aff753f15c8284429fe3e6e9a713d6367e151329576d3701967385b17b48e8\n",
      "shufflenet: 1a135065feaac7541e71be5767980aafb970e67aa6b938a68235192c823bf3ff\n",
      "mobilenet: 03c30e238db867874e66e985b6fd494d27661cd17f6ceef332415a5af88b647e\n",
      "googlenet: 7ea48ef10963fb2a794613dfb2e95e5d6c949217fddb17611cb1861951394232\n",
      "inception: 7ea48ef10963fb2a794613dfb2e95e5d6c949217fddb17611cb1861951394232\n",
      "xception: 3227a974145e3074af1fc3c9975b57b6d7b2fa2fa1e95b856f0b5f3b6af32e00\n"
     ]
    }
   ],
   "source": [
    "dataset_file_path = '../../cnn_design-space/cnnbench/dataset/dataset_mini.json'\n",
    "config_file_path = '../../cnn_design-space/cnnbench/tests/config_all-ops.yaml'\n",
    "\n",
    "graphLib = GraphLib.load_from_dataset(dataset_file_path)\n",
    "\n",
    "with open(config_file_path) as config_file:\n",
    "    try:\n",
    "        config = yaml.safe_load(config_file)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "models_mini = ['vgg11', 'vgg13', 'vgg16', 'vgg19', 'resnet18', 'resnet34', \n",
    "               'resnet50', 'resnet101', 'resnet152', 'shufflenet', 'mobilenet', 'googlenet',\n",
    "               'inception', 'xception']\n",
    "\n",
    "# Create a dictionary of hashes for all manual models in dataset_mini\n",
    "manual_models_hashes = {}\n",
    "graphLib_hashes = [graph.hash for graph in graphLib.library]\n",
    "for model_name in models_mini:\n",
    "    model = manual_models.get_manual_graph(config, model_name=model_name)\n",
    "    manual_models_hashes[model_name] = model.hash\n",
    "    \n",
    "    # Check if this model is in graphLib\n",
    "    assert model.hash in graphLib_hashes, f'{model_name} is not in graphLib'\n",
    "    \n",
    "    print(f'{model_name}: {model.hash}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset: 57108480\n",
      "SPRING present in the dataset: False\n"
     ]
    }
   ],
   "source": [
    "accel_embeddings_file_path = '../../accelerator_design-space/accelbench/embeddings/embeddings.pkl'\n",
    "\n",
    "# Initialize Accelerator embeddings\n",
    "accel_embeddings = pickle.load(open(accel_embeddings_file_path, 'rb'))\n",
    "accel_embeddings = np.array(accel_embeddings)\n",
    "\n",
    "print(f'Size of the dataset: {accel_embeddings.shape[0]}')\n",
    "\n",
    "# Check if SPRING is there in accel_embeddings\n",
    "spring_embedding = np.array([2e0, 16e0, 8e0, 4e0, 8e0, 3e0, 3e0, 1e0, 12e0, 24e0, 4e0, 1e0, 1e0])\n",
    "spring_present = False\n",
    "\n",
    "for accel_idx in range(accel_embeddings.shape[0]):\n",
    "    if (spring_embedding == accel_embeddings[accel_idx, :]).all(): spring_present = True\n",
    "        \n",
    "print(f'SPRING present in the dataset: {spring_present}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accel_hash for SPRING and vgg11: 08a0734b7c753fd8940a5977dfe968cebfe7f5d0a0d6af13837b7c0623bb4b72\n",
      "Job ID: 39257903\n",
      "\n",
      "accel_hash for SPRING and vgg13: fa909baf0301c2d43cb80c4935fea98b4a3a13fd97185428fdda12b1d1d0d080\n",
      "Job ID: 39257904\n",
      "\n",
      "accel_hash for SPRING and vgg16: 02bd3dacf4b06d0e078d0453d39e501271f350fc01c25f716f92bb2bd2f7f2b5\n",
      "Job ID: 39257905\n",
      "\n",
      "accel_hash for SPRING and vgg19: 19bf3b9956047868d1b5546f69595d16b86f440778b28908ab2a61e16849859c\n",
      "Job ID: 39257906\n",
      "\n",
      "accel_hash for SPRING and resnet18: d8538572e9c68de1d836917553c56899474ed7b2a678094a1b80536f384ed60b\n",
      "Job ID: 39257907\n",
      "\n",
      "accel_hash for SPRING and resnet34: 339a5e3d9d2e22ef9c88b1f39df246598c457684643fd6ce8cdd1db5df4b83ea\n",
      "Job ID: 39257908\n",
      "\n",
      "accel_hash for SPRING and resnet50: 27061773536be6deea1e3e9a4e6eb4f19331b87548de395ac0fa1b7fbef571ee\n",
      "Job ID: 39257909\n",
      "\n",
      "accel_hash for SPRING and resnet101: 05757f512c3da8cb7188c7faf010668ac94663099b72cb22de1667ed54294ca2\n",
      "Job ID: 39257910\n",
      "\n",
      "accel_hash for SPRING and resnet152: 33e627ae0e10b466a3732c9411b91cf3ed956cdedde6784443dd6940dff6220c\n",
      "Job ID: 39257912\n",
      "\n",
      "accel_hash for SPRING and shufflenet: 774626463f634f909e566043957474d1f2b5eb5aaaa6482c9c123787710cd950\n",
      "Job ID: 39257913\n",
      "\n",
      "accel_hash for SPRING and mobilenet: 63bd29899005bdd1f2bce7c1f8f67588408315a9ef5c39b12d000419376b973d\n",
      "Job ID: 39257914\n",
      "\n",
      "accel_hash for SPRING and googlenet: de8133c28933027135b4167ce4e7c77ae6352064e33d656dd2547556cbf9f6b2\n",
      "Job ID: 39257915\n",
      "\n",
      "accel_hash for SPRING and inception: de8133c28933027135b4167ce4e7c77ae6352064e33d656dd2547556cbf9f6b2\n",
      "Job ID: 39257916\n",
      "\n",
      "accel_hash for SPRING and xception: ef2574e01ab535e73c7176fd67ef38e3e47c74a91ab39f468b91d0bff6053c58\n",
      "Job ID: 39257917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run AccelBench simulations with SPRING and all CNN manual models\n",
    "\n",
    "models_dir = '/scratch/gpfs/stuli/accelerator_co-design'\n",
    "cnn_models_dir = os.path.join(models_dir, 'cnnbench_models', config['dataset'])\n",
    "accel_models_dir = os.path.join(models_dir, 'accelbench_models')\n",
    "\n",
    "for cnn_model_name, cnn_model_hash in manual_models_hashes.items():\n",
    "    accel_cnn_str = str(spring_embedding).replace('\\n', '') \\\n",
    "        + graphLib.get_graph(model_hash=cnn_model_hash)[0].hash\n",
    "    accel_hash = hashlib.sha256(accel_cnn_str.encode('utf-8')).hexdigest()\n",
    "    print(f'accel_hash for SPRING and {cnn_model_name}: {accel_hash}')\n",
    "    \n",
    "    args = ['--dataset', config['dataset']]\n",
    "    args.extend(['--cluster', 'della'])\n",
    "    args.extend(['--id', 'stuli'])\n",
    "    args.extend(['--autotune', '0'])\n",
    "    args.extend(['--cnn_model_hash', cnn_model_hash])\n",
    "    args.extend(['--cnn_model_dir', os.path.join(cnn_models_dir, cnn_model_hash)])\n",
    "    args.extend(['--cnn_config_file', config_file_path])\n",
    "    args.extend(['--graphlib_file', dataset_file_path])\n",
    "    args.extend(['--train_cnn', '0'])\n",
    "    args.extend(['--accel_hash', accel_hash])\n",
    "    args.extend(['--accel_emb', '\\\\\"' + str(spring_embedding).replace('\\n', '')[1:-1].replace(',', '') + '\\\\\"'])\n",
    "    args.extend(['--accel_model_file', os.path.join(accel_models_dir, accel_hash) + '.pkl'])\n",
    "    \n",
    "    slurm_stdout = subprocess.check_output(\n",
    "        f'ssh della-gpu \"cd accelerator_co-design/boshcode; source ./job_scripts/job_worker.sh {\" \".join(args)}\"',\n",
    "        shell=True, text=True, executable=\"/bin/bash\")\n",
    "\n",
    "    print(f'Job ID: {slurm_stdout.split()[-1]}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnnbench [~/.conda/envs/cnnbench/]",
   "language": "python",
   "name": "conda_cnnbench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
