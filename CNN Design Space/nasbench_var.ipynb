{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nasbench_var.ipynb","provenance":[{"file_id":"https://github.com/google-research/nasbench/blob/master/NASBench.ipynb","timestamp":1608040131043}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"vl1oLYux3FhJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608116907235,"user_tz":-330,"elapsed":74774,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}},"outputId":"3ae76d80-bc6f-4d1c-e60d-78b5f7c42058"},"source":["# This code was written in TF 1.12 but should be supported all the way through\n","# TF 1.15. Untested in TF 2.0+.\n","%tensorflow_version 1.x\n","\n","# Download the raw data (only 108 epoch data points, for full dataset,\n","# uncomment the second line for nasbench_full.tfrecord).\n","\n","!curl -O https://storage.googleapis.com/nasbench/nasbench_only108.tfrecord\n","# !curl -O https://storage.googleapis.com/nasbench/nasbench_full.tfrecord\n","\n","# Clone and install the code and dependencies.\n","\n","!git clone https://github.com/google-research/nasbench\n","!pip install ./nasbench\n","\n","# Initialize the NASBench object which parses the raw data into memory (this\n","# should only be run once as it takes up to a few minutes).\n","from nasbench import api\n","\n","import sys\n","if './nasbench/nasbench/' not in sys.path:\n","  sys.path.append('./nasbench/nasbench/')\n","\n","from api import *\n","\n","dataset_file = 'nasbench_only108.tfrecord'\n","\n","# Use nasbench_full.tfrecord for full dataset (run download command above).\n","nasbench = api.NASBench(dataset_file)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  498M  100  498M    0     0  88.4M      0  0:00:05  0:00:05 --:--:-- 91.0M\n","Cloning into 'nasbench'...\n","remote: Enumerating objects: 96, done.\u001b[K\n","remote: Total 96 (delta 0), reused 0 (delta 0), pack-reused 96\u001b[K\n","Unpacking objects: 100% (96/96), done.\n","Processing ./nasbench\n","Requirement already satisfied: tensorflow>=1.12.0 in /tensorflow-1.15.2/python3.6 (from nasbench==1.0) (1.15.2)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.36.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.2.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.34.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (3.12.4)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.6 (from tensorflow>=1.12.0->nasbench==1.0) (1.15.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.15.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-1.15.2/python3.6 (from tensorflow>=1.12.0->nasbench==1.0) (1.0.8)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.12.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.10.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.1.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (3.3.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.1.0)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.6 (from tensorflow>=1.12.0->nasbench==1.0) (1.15.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (0.8.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->nasbench==1.0) (1.18.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow>=1.12.0->nasbench==1.0) (50.3.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.12.0->nasbench==1.0) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.12.0->nasbench==1.0) (3.3.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=1.12.0->nasbench==1.0) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow>=1.12.0->nasbench==1.0) (3.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow>=1.12.0->nasbench==1.0) (3.4.0)\n","Building wheels for collected packages: nasbench, gast\n","  Building wheel for nasbench (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nasbench: filename=nasbench-1.0-cp36-none-any.whl size=46788 sha256=9d11c05ec934d03ffe698b7ac0245a4fdfaaed9097e107b7597f6c9fc1b9e8d2\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-v05x6p90/wheels/4b/19/99/1d5fdfe30f8b16fab91e900808f4f7e5adc38e602c84970ad5\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=9336d2e2df75a2106786c6502796b2e8ea7ab623397110c50f923f47b26f8573\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built nasbench gast\n","Installing collected packages: nasbench, gast\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","Successfully installed gast-0.2.2 nasbench-1.0\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/nasbench/lib/training_time.py:130: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/nasbench/lib/training_time.py:174: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/nasbench/lib/evaluate.py:30: The name tf.train.NanLossDuringTrainingError is deprecated. Please use tf.estimator.NanLossDuringTrainingError instead.\n","\n","Loading dataset from file... This may take a few minutes...\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/nasbench/api.py:146: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use eager execution and: \n","`tf.data.TFRecordDataset(path)`\n","Loaded dataset in 54 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oFhFRmck7NzM","executionInfo":{"status":"ok","timestamp":1608116907240,"user_tz":-330,"elapsed":54642,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}}},"source":["# Standard imports\n","import copy\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","\n","# Useful constants\n","INPUT = 'input'\n","OUTPUT = 'output'\n","CONV3X3 = 'conv3x3-bn-relu'\n","CONV1X1 = 'conv1x1-bn-relu'\n","MAXPOOL3X3 = 'maxpool3x3'\n","NUM_VERTICES = 7\n","MAX_EDGES = 9\n","EDGE_SPOTS = NUM_VERTICES * (NUM_VERTICES - 1) / 2   # Upper triangular matrix\n","OP_SPOTS = NUM_VERTICES - 2   # Input/output vertices are fixed\n","ALLOWED_OPS = [CONV3X3, CONV1X1, MAXPOOL3X3]\n","ALLOWED_EDGES = [0, 1]   # Binary adjacency matrix"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i9SOVEvxrwwa","executionInfo":{"status":"ok","timestamp":1608116925636,"user_tz":-330,"elapsed":1119,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}},"outputId":"14549c74-2433-418c-f93a-33e9fa7cb78c"},"source":["count = 0\r\n","max_count = 6\r\n","\r\n","for serialized_row in tf.python_io.tf_record_iterator(dataset_file):\r\n","  # Parse the data from the data file.\r\n","  module_hash, epochs, raw_adjacency, raw_operations, raw_metrics = (\r\n","      json.loads(serialized_row.decode('utf-8')))\r\n","\r\n","  dim = int(np.sqrt(len(raw_adjacency)))\r\n","  adjacency = np.array([int(e) for e in list(raw_adjacency)], dtype=np.int8)\r\n","  adjacency = np.reshape(adjacency, (dim, dim))\r\n","  operations = raw_operations.split(',')\r\n","  metrics = model_metrics_pb2.ModelMetrics.FromString(\r\n","      base64.b64decode(raw_metrics))\r\n","\r\n","  # Evaluation statistics at the end of training\r\n","  final_evaluation = metrics.evaluation_data[2]\r\n","  training_time = final_evaluation.training_time\r\n","  train_accuracy = final_evaluation.train_accuracy\r\n","  validation_accuracy = (\r\n","      final_evaluation.validation_accuracy)\r\n","  test_accuracy = final_evaluation.test_accuracy\r\n","  trainable_params = metrics.trainable_parameters\r\n","\r\n","  print(f'Module {count//3+1}.{count%3+1} \\nAdjacency matrix: \\n{adjacency} \\nOperations: {operations} \\nTrainable parameters: {trainable_params}')\r\n","\r\n","  print(f'Train Accuracy: {train_accuracy} \\nValidation Accuracy: {validation_accuracy} \\nTest Accuracy: {test_accuracy}\\n')\r\n","\r\n","  count += 1\r\n","  if count == max_count:\r\n","    break"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Module 1.1 \n","Adjacency matrix: \n","[[0 1 0 0 1 1 0]\n"," [0 0 1 0 0 0 0]\n"," [0 0 0 1 0 0 1]\n"," [0 0 0 0 0 1 0]\n"," [0 0 0 0 0 1 0]\n"," [0 0 0 0 0 0 1]\n"," [0 0 0 0 0 0 0]] \n","Operations: ['input', 'conv3x3-bn-relu', 'maxpool3x3', 'conv3x3-bn-relu', 'conv3x3-bn-relu', 'conv1x1-bn-relu', 'output'] \n","Trainable parameters: 8555530\n","Train Accuracy: 1.0 \n","Validation Accuracy: 0.9241786599159241 \n","Test Accuracy: 0.9211738705635071\n","\n","Module 1.2 \n","Adjacency matrix: \n","[[0 1 0 0 1 1 0]\n"," [0 0 1 0 0 0 0]\n"," [0 0 0 1 0 0 1]\n"," [0 0 0 0 0 1 0]\n"," [0 0 0 0 0 1 0]\n"," [0 0 0 0 0 0 1]\n"," [0 0 0 0 0 0 0]] \n","Operations: ['input', 'conv3x3-bn-relu', 'maxpool3x3', 'conv3x3-bn-relu', 'conv3x3-bn-relu', 'conv1x1-bn-relu', 'output'] \n","Trainable parameters: 8555530\n","Train Accuracy: 1.0 \n","Validation Accuracy: 0.9245793223381042 \n","Test Accuracy: 0.9190705418586731\n","\n","Module 1.3 \n","Adjacency matrix: \n","[[0 1 0 0 1 1 0]\n"," [0 0 1 0 0 0 0]\n"," [0 0 0 1 0 0 1]\n"," [0 0 0 0 0 1 0]\n"," [0 0 0 0 0 1 0]\n"," [0 0 0 0 0 0 1]\n"," [0 0 0 0 0 0 0]] \n","Operations: ['input', 'conv3x3-bn-relu', 'maxpool3x3', 'conv3x3-bn-relu', 'conv3x3-bn-relu', 'conv1x1-bn-relu', 'output'] \n","Trainable parameters: 8555530\n","Train Accuracy: 1.0 \n","Validation Accuracy: 0.9304887652397156 \n","Test Accuracy: 0.9215745329856873\n","\n","Module 2.1 \n","Adjacency matrix: \n","[[0 1 0 0 0 0 0]\n"," [0 0 1 0 0 0 0]\n"," [0 0 0 1 0 0 0]\n"," [0 0 0 0 1 1 1]\n"," [0 0 0 0 0 1 0]\n"," [0 0 0 0 0 0 1]\n"," [0 0 0 0 0 0 0]] \n","Operations: ['input', 'conv1x1-bn-relu', 'conv1x1-bn-relu', 'conv3x3-bn-relu', 'conv1x1-bn-relu', 'conv3x3-bn-relu', 'output'] \n","Trainable parameters: 5878154\n","Train Accuracy: 0.9993990659713745 \n","Validation Accuracy: 0.8942307829856873 \n","Test Accuracy: 0.8916265964508057\n","\n","Module 2.2 \n","Adjacency matrix: \n","[[0 1 0 0 0 0 0]\n"," [0 0 1 0 0 0 0]\n"," [0 0 0 1 0 0 0]\n"," [0 0 0 0 1 1 1]\n"," [0 0 0 0 0 1 0]\n"," [0 0 0 0 0 0 1]\n"," [0 0 0 0 0 0 0]] \n","Operations: ['input', 'conv1x1-bn-relu', 'conv1x1-bn-relu', 'conv3x3-bn-relu', 'conv1x1-bn-relu', 'conv3x3-bn-relu', 'output'] \n","Trainable parameters: 5878154\n","Train Accuracy: 0.999098539352417 \n","Validation Accuracy: 0.8959335088729858 \n","Test Accuracy: 0.8862179517745972\n","\n","Module 2.3 \n","Adjacency matrix: \n","[[0 1 0 0 0 0 0]\n"," [0 0 1 0 0 0 0]\n"," [0 0 0 1 0 0 0]\n"," [0 0 0 0 1 1 1]\n"," [0 0 0 0 0 1 0]\n"," [0 0 0 0 0 0 1]\n"," [0 0 0 0 0 0 0]] \n","Operations: ['input', 'conv1x1-bn-relu', 'conv1x1-bn-relu', 'conv3x3-bn-relu', 'conv1x1-bn-relu', 'conv3x3-bn-relu', 'output'] \n","Trainable parameters: 5878154\n","Train Accuracy: 0.9958934187889099 \n","Validation Accuracy: 0.8937299847602844 \n","Test Accuracy: 0.8815104365348816\n","\n"],"name":"stdout"}]}]}